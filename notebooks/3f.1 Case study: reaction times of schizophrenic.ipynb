{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives and takeaways\n",
    "1. Take a real-world experiment, write the model.\n",
    "2. Write a Metropolis sampler, including the proposal distribution.\n",
    "3. Perform inference using your sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: with thanks to Charles Lao for consulting on the structure of a suitable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "We shall work with the experiment published in Belin and Rubin [1] in 1995 that analyzed reaction times to visual stimuli in Schizophrenia.\n",
    "\n",
    "A total of 17 volunteers performed 30 repetitions of a visual task and their reaction time was measured in milliseconds. There were 6 schizophrenics and 11 healthy volunteers.\n",
    "\n",
    "Note that in the work [1], the authors do not use a Bayesian approach for estimation but apply an EM procedure.  The priors that we define in this work must therefore be our construction.\n",
    "\n",
    "Below is the original data from the experiment, available [here](http://www.stat.columbia.edu/~gelman/book/data/schiz.asc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = \"\"\"\n",
    "312 272 350 286 268 328 298 356 292 308 296 372 396 402 280 330 254 282 350 328 332 308 292 258 340 242 306 328 294 272\n",
    "354 346 384 342 302 312 322 376 306 402 320 298 308 414 304 422 388 422 426 338 332 426 478 372 392 374 430 388 354 368\n",
    "256 284 320 274 324 268 370 430 314 312 362 256 342 388 302 366 298 396 274 226 328 274 258 220 236 272 322 284 274 356\n",
    "260 294 306 292 264 290 272 268 344 362 330 280 354 320 334 276 418 288 338 350 350 324 286 322 280 256 218 256 220 356\n",
    "204 272 250 260 314 308 246 236 208 268 272 264 308 236 238 350 272 252 252 236 306 238 350 206 260 280 274 318 268 210\n",
    "590 312 286 310 778 364 318 316 316 298 344 262 274 330 312 310 376 326 346 334 282 292 282 300 290 302 300 306 294 444\n",
    "308 364 374 278 366 310 358 380 294 334 302 250 542 340 352 322 372 348 460 322 374 370 334 360 318 356 338 346 462 510\n",
    "244 240 278 262 266 254 240 244 226 266 294 250 284 260 418 280 294 216 308 324 264 232 294 236 226 234 274 258 208 380\n",
    "232 262 230 222 210 284 232 228 264 246 264 316 260 266 304 268 384 234 308 266 294 254 222 262 278 290 208 232 206 206\n",
    "318 324 282 364 286 342 306 302 280 306 256 334 332 336 360 344 480 310 336 314 392 284 292 280 320 322 286 406 352 324\n",
    "240 292 350 254 396 430 260 320 298 312 290 248 276 364 318 434 400 382 318 298 298 248 250 234 280 306 282 234 424 244\n",
    "\n",
    "276 272 264 258 278 286 314 340 334 364 286 344 312 380 262 324 310 260 280 262 364 316 270 286 326 302 300 302 344 290\n",
    "374 466 432 376 360 454 478 382 524 410 520 470 514 354 434 380 416 384 462 386 404 362 420 360 390 356 550 372 386 396\n",
    "594 1014 1586 1344 610 838 772 264 748 1076 446 314 304 1680 1700 334 256 422 302 296 354 322 276 382 502 428 544 286 650 432\n",
    "402 466 296 348 680 702 500 500 576 624 406 378 586 826 298 882 564 656 716 380 448 506 1714 748 510 810 984 458 390 642\n",
    "620 714 414 358 460 598 324 442 372 410 998 636 968 490 696 560 562 720 618 456 502 974 1032 470 462 798 716 300 586 574\n",
    "454 388 344 226 562 766 502 432 608 516 500 796 542 458 448 404 372 524 400 366 374 350 1154 558 440 348 400 460 514 450\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the first 11 lines are from controls, the last 6 from schizophrenics\n",
    "def parse_data():\n",
    "    rts, idx = [], 0\n",
    "    for line in orig_data.split('\\n'):\n",
    "        if len(line) == 0: continue\n",
    "        cat = 0 if idx < 11 else 1\n",
    "        tokens = line.split(' ')\n",
    "        rts.append(list(map(int, line.split(' '))))\n",
    "    return np.array(rts)\n",
    "\n",
    "reaction_times = parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Np, Nt = reaction_times.shape\n",
    "print('Data shows %d patients, %d trials per patient' % (Np, Nt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "_, axes = plt.subplots(6, 3, figsize=(16, 8), sharex=True)\n",
    "bins = np.linspace(reaction_times.min(), reaction_times.max(), 100)\n",
    "axes = axes.flatten()\n",
    "for isbj in range(Np):\n",
    "    axes[isbj].hist(reaction_times[isbj, :], bins)\n",
    "    axes[isbj].set_title('subject index %d [%s]' %(isbj, 'control' if isbj < 11 else '*patient*'), fontsize=14)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "Patients are stored in rows. For example data in line ```rts[0,:]``` shows reaction times in milliseconds for the first control group participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reaction_times[0:11,:].mean(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure\n",
    "Below we discuss model similar to model number 4 from Belin and Rubin [1], their richest model. The other models are not discussed in this notebook.\n",
    "\n",
    "In the following, we will use the subscript $i \\in \\{1, 2, ..., 17\\}$ to denote participants and $j \\in \\{1, 2, ..., 30\\}$ to denote trials, so for example $Y_{i,j}$ denotes observed reaction time for patient $i$ and trial $j$.\n",
    "\n",
    "It is assumed that there is a mean reaction time $\\mu$ and standard deviation $\\sigma_1$ in the control group but each participant in the study can have a slightly different mean reaction time $\\alpha_i$. Schizophrenic participants behave like the control group except in specific trials, where they exhibit an attention deficit that causes their reaction time to be increased.  The (unobserved) variable $Z_{i,j} \\in \\{0,1\\}$ denotes whether the attention deficit was present $Z_{i,j}=1$ or absent $Z_{i,j}=0$ in trial $j$ for patient $i$. The proportion of trials $\\lambda_i$ where the deficit manifests varies among patients.\n",
    "\n",
    "We may formalize the model for the control group as follows:\n",
    "\n",
    "$$Y_{i,j} \\sim {\\cal N}(\\alpha_i, \\sigma_1^2)$$\n",
    "\n",
    "and for the schizophrenia group as\n",
    "\n",
    "$$Y_{i,j} \\sim {\\cal N}(\\alpha_i, \\sigma_1^2),$$\n",
    "\n",
    "if the trial had no attention deficit present (so exactly the same as control group) and\n",
    "\n",
    "$$Y_{i,j} \\sim {\\cal N}(\\alpha_i + \\tau, \\sigma_2^2),$$\n",
    "\n",
    "if there was an attention deficit.  Note the different standard deviation used to model the reaction time under attention deficit.  In the model below, we use $Z_{i,j}$ to keep track of which mode is active in the trials performed by schizophrenic patients.  We additionally posit that \n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "\\lambda_i &\\sim& \\text{U}(0,1) \\\\\n",
    "Z_{i,j} &\\sim& \\text{Bernoulli}(\\lambda), \\\\\n",
    "\\mu &\\sim& {\\cal N}(400, 100)\\\\\n",
    "\\alpha_i &\\sim& {\\cal N}(\\mu, 50), \\\\\n",
    "\\tau &\\sim& \\text{HalfNormal}(50), \\\\\n",
    "\\sigma_1 &\\sim& \\text{HalfNormal}(100), \\\\\n",
    "\\sigma_2 &\\sim& \\text{HalfNormal}(100). \\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of solution\n",
    "1. Select priors for the problem (see below).\n",
    "2. Write down the structure of the model, write the ```log_prior``` and ```log_likelihood``` functions.\n",
    "3. Write a proposal distribution, function ```proposal``` to suggest a new state from current state.\n",
    "4. Write (or modify, from notebook 3f) the Metropolis sampler.\n",
    "5. Sample outputs and evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working sampler using PyMC3\n",
    "\n",
    "So that the structure of the model is clear, we provide a working example of a sampler using the PyMC3 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as schizo_model:\n",
    "    mu = pm.Normal('mu', 400, 100)\n",
    "    alphas_ = pm.Normal('alphas_', 0, 50., shape=(Np,1))\n",
    "    alphas = pm.Deterministic('alphas', mu + alphas_)\n",
    "    \n",
    "    sigma_ctrl = pm.HalfNormal('sigma_ctrl', 100)\n",
    "    sigma_pat = pm.HalfNormal('sigma_pat', 100)\n",
    "    tau = pm.HalfNormal('tau', 100)\n",
    "    \n",
    "    lambdas = pm.Uniform('lambdas', 0., 1., shape=(6,1))\n",
    "    Z = pm.Bernoulli('Z', lambdas, shape=(6, Nt))\n",
    "\n",
    "    controls = pm.Normal('control',\n",
    "                      alphas[:11,:],\n",
    "                      sigma_ctrl,\n",
    "                      observed=reaction_times[:11, :])\n",
    "\n",
    "    patients = pm.Normal('patients',\n",
    "                       alphas[11:,:] + Z*tau,\n",
    "                       tt.switch(Z, sigma_pat, sigma_ctrl),\n",
    "                       observed=reaction_times[11:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with schizo_model:\n",
    "    trace = pm.sample(draws=2000,\n",
    "                      tune=1000,\n",
    "                      chains=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, varnames=['mu', 'tau', 'lambdas', 'sigma_ctrl', 'sigma_pat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with schizo_model:\n",
    "    _ = pm.traceplot(trace, varnames=['mu','tau', 'alphas', 'lambdas', 'sigma_ctrl', 'sigma_pat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of results and comparison to data\n",
    "We expect that for patients where some reaction times are very high, the model will infer that those are affected by the deficit and model them differently than the rest of the patient trials.\n",
    "\n",
    "Thus:\n",
    "- $\\sigma_2$ should be much higher than $\\sigma_1$ - check\n",
    "- $\\alpha_i$ should be very close to data mean in control group and should be much lower than data mean in groups with high attention deficit trials\n",
    "- $\\lambda_i$ should vary strongly across patients\n",
    "- $Z_{i,j}$ should vary across trials at least in patients 13-16\n",
    "- $Z_{i,j}$ correlate with reaction time positively ($Z_{i,j}=1$ means the reaction time should be high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(trace['alphas'],axis=0)-np.mean(reaction_times[:Np,:],axis=1)[:, np.newaxis], 'o')\n",
    "plt.title('Difference in $\\\\alpha_i$ and data mean vs. patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs = trace['Z']\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "labels = []\n",
    "for k in range(6):\n",
    "    plt.plot(np.mean(Zs[:,k,:], axis=0), 'o-')\n",
    "    labels.append('Patient %d' % (k+11))\n",
    "\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(11, 17), np.mean(np.mean(Zs, axis=0), axis=1), 'o-')\n",
    "plt.title('Proportion of trials with attn deficit')\n",
    "plt.xlabel('Patient index [-]')\n",
    "plt.ylabel('avg(Z)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that patients 13, 14 and 15 have the highest attention deficit proportion, which seems to correspond to the initial data plots well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for k in range(6):\n",
    "    plt.subplot(2,3,k+1)\n",
    "    ts = reaction_times[k+11,:]\n",
    "    Zs_k = np.mean(Zs[:,k,:], axis=0)\n",
    "    plt.scatter(ts, Zs_k)\n",
    "    plt.ylim([0,1])\n",
    "    plt.title('Patient %d' % (k+11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "According to our model, we would expect that the probability of $Z_{i,j}$ being one for low reaction times would be low and high/high would hold as well.  In the plots below, this does not hold and for some very small reaction times, we still see that the model claims that some very small reaction times actually result from attention deficits. Why is that?\n",
    "\n",
    "Hint: note that if you replace the ```tt.switch(...)``` statement with ```sigma_ctrl```, this effect disappears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn!\n",
    "Now let's work on writing our own sampler.  While ```PyMC3``` uses a NUTS sampler plus Gibbs sampling for the latent variables $Z_{i,j}$, we will build the entire system using Metropolis and compare our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of state\n",
    "Although as much freedom should be provided to write the code, there is a recommendation below on how to structure the state variable as a dictionary because it helps to improve the readability of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the initial point\n",
    "lambda_initial = 0.5\n",
    "\n",
    "# here's a nice initial point :)\n",
    "v_init = { 'mu' : 400,\n",
    "           'delta_alphas': np.random.randn(Np) * 50,\n",
    "           'tau': 50,\n",
    "           'sigma_ctrl': 100,\n",
    "           'sigma_pat': 100,\n",
    "           'lambdas' : np.ones(6,) * lambda_initial,\n",
    "           'Zij': np.where(np.random.uniform(size=(6,Nt)) < lambda_initial, np.ones((6,Nt)), np.zeros((6,Nt)))\n",
    "         }\n",
    "\n",
    "MD = {\n",
    "        'mu': (1, 0, np.inf),\n",
    "        'delta_alphas': (Np, 0, np.inf),\n",
    "        'tau' : (1, 0, np.inf),\n",
    "        'sigma_ctrl' : (1, 0, np.inf),\n",
    "        'sigma_pat' : (1, 0, np.inf),\n",
    "        'lambdas': (6, 0, 1), \n",
    "    }\n",
    "\n",
    "sigmas_0 = {\n",
    "        'mu': 40,\n",
    "        'delta_alphas': 10,\n",
    "        'tau' : 10,\n",
    "        'sigma_ctrl' : 20,\n",
    "        'sigma_pat' : 20,\n",
    "        'lambdas': 0.1,\n",
    "        'Zij': 0.2\n",
    "    }\n",
    "\n",
    "def gen(v0, sigmas):\n",
    "    def one(key, fd):\n",
    "        size, lower, upper = fd, -np.inf, np.inf\n",
    "        if isinstance(fd, tuple):\n",
    "            size, lower, upper = fd    \n",
    "        val = v0[key] + sigmas[key] * np.random.randn(size)\n",
    "        #val = np.clip(val, lower, upper)\n",
    "        if size == 1:\n",
    "            val = val[0]\n",
    "        return val\n",
    "    \n",
    "    d= {}\n",
    "    for key, fd in MD.items():\n",
    "        d[key] = one(key, fd)\n",
    "    \n",
    "    zs = np.copy(v0['Zij'])\n",
    "    for i, l in enumerate(d['lambdas']):\n",
    "        for j in range(Nt):\n",
    "            if np.random.uniform() < sigmas['Zij']:\n",
    "                zs[i,j] = 1.0 if np.random.uniform() < 0.5 else 0.0\n",
    "    d['Zij'] = zs\n",
    "    for k,v in d.items():\n",
    "        if type(v) == np.ndarray:\n",
    "            assert v.shape == v0[k].shape\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, halfnorm, uniform, bernoulli\n",
    "\n",
    "def log_prior(v):\n",
    "    assert len(v['Zij']) == len(v['lambdas']) == 6\n",
    "    PS = (norm.logpdf(v['mu'], 400, 100),\n",
    "          norm.logpdf(v['delta_alphas'], v['mu'], 50).sum(),\n",
    "            halfnorm.logpdf(v['tau'], scale=50),\n",
    "            halfnorm.logpdf(v['sigma_ctrl'], scale=100),\n",
    "            halfnorm.logpdf(v['sigma_pat'], scale=100),\n",
    "            uniform.logpdf(v['lambdas']).sum(),\n",
    "            np.sum(bernoulli.logpmf(v['Zij'][i,:], v['lambdas'][i]).sum() for i in range(6))\n",
    "           )\n",
    "    #print(PS)\n",
    "    return sum(PS)\n",
    "\n",
    "def log_likelihood(v, X=reaction_times):\n",
    "    assert len(v['delta_alphas']) == Np\n",
    "    s = 0.0\n",
    "    # control\n",
    "    for i in range(11):\n",
    "        s += norm.logpdf(X[i, :], v['delta_alphas'][i], v['sigma_ctrl']).sum()\n",
    "        #print(i, s)\n",
    "    \n",
    "    # patients\n",
    "    for i in range(6):\n",
    "        zs = v['Zij'][i]\n",
    "        p_sigmas = v['sigma_pat'] * zs + (1-zs) * v['sigma_ctrl']\n",
    "        assert all( s in [v['sigma_pat'], v['sigma_ctrl']] for s in p_sigmas)\n",
    "        p_alphas = zs * v['tau'] + v['delta_alphas'][11 + i]\n",
    "        s += norm.logpdf(X[11 + i, :], p_alphas, p_sigmas).sum()\n",
    "        #print(i, s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "\n",
    "def log_posterior(v):\n",
    "    return log_prior(v) + log_likelihood(v)\n",
    "\n",
    "print(log_posterior(v_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def metropolis(x0, logp, N, gen, verbose=False):\n",
    "    states = [x0]\n",
    "    logps = [logp(x0)]\n",
    "    acc = 0\n",
    "    for i in range(N):\n",
    "        if verbose:\n",
    "            c = ''\n",
    "            if i % 5000 == 4999:\n",
    "                c = ''\n",
    "                print(\"%.2f%%\"%(100*i/N))\n",
    "            elif i % 1000 == 999:\n",
    "                c = '1'\n",
    "            elif i % 100 == 99:\n",
    "                c = '.'\n",
    "            print(c, end='')\n",
    "        \n",
    "        xold = states[-1]\n",
    "        lold = logps[-1]\n",
    "        \n",
    "        xnext = gen(xold, i/N)\n",
    "        lnext = logp(xnext)\n",
    "\n",
    "        u = np.random.uniform()\n",
    "        if lnext - lold > np.log(u):\n",
    "            states.append(xnext)\n",
    "            logps.append(lnext)\n",
    "            acc += 1\n",
    "        else:\n",
    "            # this is different from Monte Carlo rejection sampler\n",
    "            # if we reject a new sample we 're-sample' the current state\n",
    "            states.append(xold)\n",
    "            logps.append(lold)\n",
    "    if verbose:        \n",
    "        print()\n",
    "    print(\"acceptance = %.2f%%\"%(100*acc/N))\n",
    "    return acc / N, states, logps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# SUCH pain to get working values\n",
    "sigmas_1 = {\n",
    "        'mu': 6.4,\n",
    "        'delta_alphas': 3.2,\n",
    "        'tau' : 12.0,\n",
    "        'sigma_ctrl' : 2.0,\n",
    "        'sigma_pat' : 8.0,\n",
    "        'lambdas': 0.01,\n",
    "        'Zij':0.1\n",
    "    }\n",
    "\n",
    "def one(i):\n",
    "    np.random.seed(i)\n",
    "    return metropolis(v_init, log_posterior, 100000, (lambda v,p : gen(v, sigmas_1)))\n",
    "\n",
    "RUNS = 4\n",
    "with Pool(4) as p:\n",
    "    runs = p.map(one, range(RUNS))\n",
    "\n",
    "#acc, S0, L0 = metropolis(v_init, log_posterior, 4000, (lambda v,p : gen(v, sigmas_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CUTOFF = 0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.hist(L)\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "for i, k in enumerate(['mu', 'tau', 'sigma_ctrl', 'sigma_pat']):\n",
    "    for acc, SS, L in runs:\n",
    "        S = SS[CUTOFF:]\n",
    "        values = [s[k] for s in S]\n",
    "        \n",
    "        plt.subplot(4,2,i*2 + 1)\n",
    "        plt.title(k)\n",
    "        sns.kdeplot(values)\n",
    "        plt.subplot(4,2,i*2 + 2)\n",
    "        plt.title(k)\n",
    "        S = S[CUTOFF:]\n",
    "        values = [s[k] for s in S]\n",
    "        plt.plot(values)\n",
    "        \n",
    "    \n",
    "plt.show()\n",
    "for i in range(6):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for acc, SS, L in runs:\n",
    "        S = SS[CUTOFF:]\n",
    "\n",
    "        values = [s['lambdas'][i] for s in S]\n",
    "        plt.subplot(1,2,1)\n",
    "        sns.kdeplot(values)\n",
    "        plt.title('lambda %d'%i)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(values)\n",
    "        plt.title('lambda %d'%i)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for i in range(4):\n",
    "    for acc, SS, L in runs:\n",
    "        S = SS[CUTOFF:]\n",
    "        values = [s['delta_alphas'][i] for s in S]\n",
    "        plt.subplot(1,2,1)\n",
    "        sns.kdeplot(values)\n",
    "        plt.title('alphas')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(values)\n",
    "        plt.title('alphas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final remarks\n",
    "Thanks to Charles Lao for consulting on fitting model structure for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
